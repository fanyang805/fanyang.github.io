<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>Fan's site | Object Detection using YOLO model</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->
<!-- 
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">
 -->
<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>"> -->
<link rel="shortcut icon" href="/assets/img/favicon.ico">
<link rel="stylesheet" href="/assets/css/main.css">

<link rel="canonical" href="/projects/computer-vision/yolo/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

  <script src="/assets/js/theme.js"></script>
  <!-- Load DarkMode JS -->
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.1.2/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="/">
        <i class="fas fa-fan fa-spin"></i>
       Fan's site
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              About
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              Blog 
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/course-work/">
                Course Work
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                Projects
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/research/">
                Research
                
              </a>
          </li>
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/services/">
                Services
                
              </a>
          </li>
          
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">Object Detection using YOLO model</h1>
    <!-- <p class="post-description">In this project, a real-time object detection application is created for the self-driving car using YOLO model. Given images taken from the car-mounted camera, the program outputs a list of bounding boxes indicating not only the position and size of objects but also the class of objects. In particular, a Deep CNN is used to convert the preprocessed image to an encoding, from which the bounding boxes with high probability is computed by non-max suppression. 
</p> -->
  </header>

  <article>
    <p>The real-time object detection is a key component of the autonomous driving system. It is widely used for problems like collision-avoidance, navigation, mapping. In this project, an object detection system is created using YOLO model<sup>[1]</sup>.</p>

<p>It is assumed that a camera mounted on the car takes pictures of the road every few seconds while driving. The YOLO model takes pictures of road as input and outputs a list of bounding boxes along with the recognized classes, as shown in figure below.</p>

<div class="row justify-content-center">
    <div class="col">
        <div class="w-50 mx-auto" style="background-color: white;">
            <img class="img-fluid" src="/projects/computer-vision/YOLO/assets/img/yolo_demo.gif" alt="" />
        </div>
    </div>
</div>
<div class="caption">
Real-time Object Detection
</div>
<p><br /></p>

<h2 id="overview-of-yolo">Overview of YOLO</h2>

<p>In this project, we use the “You Only Look Once” (YOLO) algorithm which achieves the high accuracy and real-time object detection. In particular, the predication is made by only one forward propagation through a Deep CNN.</p>

<p>The Encoding architecture for YOLO is shown as following:</p>

<div class="row justify-content-center">
    <div class="col">
        <div class="w-75 mx-auto" style="background-color: white;">
            <img class="img-fluid" src="/projects/computer-vision/YOLO/assets/img/architecture.png" alt="" />
        </div>
    </div>
</div>
<div class="caption">
Encoding architecture for YOLO<sup>[2]</sup>
</div>
<p><br /></p>

<p>The input of the Deep CNN is image of size (608, 608, 3). The output of the network is an encoding of size (19, 19, 5, 85). More specifically, the input 608X608 image is partitioned by a 19X19 matrix in which each entry represents a part of region in the image. Each region is further represented by a 5X85 matrix, where each row indicates an anchor box with specific height/width ratio. Each anchor box contains information of the bounding box and classification, i.e., \((p_c, b_x, b_y, b_h, b_w, c_1, ..., c_{80})\) where \(p_c\) indicates the probability that the center of an object is in the bounding box. \(b_x, b_y\) refer to the coordinates of the center of bounding box in the current region and \(b_w, b_h\) represent the width and height of the bounding box. \(c_i\) indicates the probability that the object belongs to class i. Therefore, there are \(19\times19\times5=1805\) bounding boxes with probability \(\max_i \ p_c c_i\) for class \(\mathrm{argmax}_i \ p_c c_i\). This probability is called the score of box.</p>

<p>To reduce the number of boxes in the output, we can remove bounding box with score less than a threshold value.</p>

<div class="row justify-content-center">
    <div class="col">
        <div class="w-50 mx-auto" style="background-color: white;">
            <img class="img-fluid" src="/projects/computer-vision/YOLO/assets/img/anchor_map.png" alt="" />
        </div>
    </div>
</div>
<div class="caption">
Bounding boxes predicated by the network<sup>[2]</sup>
</div>
<p><br /></p>

<p>As it is shown in figure above, some object is detected by multiple bounding boxes in different cells. To get more specific solution, we need to select one box when muliple overlapping boxes detect same object. The technique used here is called non-max suppression. The key steps are following:</p>

<ol>
  <li>Remove boxes with score less than the threshold.</li>
  <li>Select the box with the highest score.</li>
  <li>Compute the intersection over union (IoU) with other overlapping boxes. Remove boxes that have high IoU.</li>
  <li>Go back to step 2 until no more boxes with lower score the current one.</li>
</ol>

<h2 id="code-explanation">Code Explanation</h2>

<ol>
  <li>
    <p><code class="language-plaintext highlighter-rouge">yolo_filter_boxes(box_confidence, boxes, box_class_probs, threshold)</code>: Filter boxes by thresholding on object and class confidence. Given the encoding (i.e., <code class="language-plaintext highlighter-rouge">box_confidence</code> \(p_c\), <code class="language-plaintext highlighter-rouge">boxes</code> \(b_x, b_y, b_h, b_w\), <code class="language-plaintext highlighter-rouge">box_class_probs</code> \(c_1,...,c_{80}\)), return the boxes with probability greater than <code class="language-plaintext highlighter-rouge">threshold</code>.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">yolo_non_max_suppression(scores, boxes, classes, max_boxes, iou_threshold)</code>: Implement non-max suppression (step 2 to 4).</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">yolo_eval(yolo_outputs, image_shape, max_boxes, score_threshold, iou_threshold)</code>: Convert the output of YOLO encoding which contains a large number of bounding boxes to a smaller number of the selected boxes after the filtering.</p>
  </li>
</ol>

<p>The classes of objects are defined in <code class="language-plaintext highlighter-rouge">coco_classes.txt</code>. The five anchor boxes are defined in <code class="language-plaintext highlighter-rouge">yolo_anchors.txt</code>. Due to the limitation of the hardware, we use a pre-trained YOLO model <code class="language-plaintext highlighter-rouge">yolo.h5</code> which can be obtained from repository <a href="https://github.com/allanzelener/YAD2K">https://github.com/allanzelener/YAD2K</a>.</p>

<p>The dataset used in this project is downloaded from <a href="https://doc.bdd100k.com/download.html#">BDD100K dataset</a>.</p>

<p>To detect objects from the dataset, run <code class="language-plaintext highlighter-rouge">python yolo_demo.py</code> at the root of project directory.</p>

<h3 id="references">References</h3>

<ol>
  <li>
    <p><strong>You Only Look Once: Unified, Real-Time Object Detection</strong><br />
Joseph Redmon and Santosh Kumar Divvala and Ross B. Girshick and Ali Farhadi. CoRR 2015; <a href="https://arxiv.org/abs/1506.02640">abs/1506.02640</a>.</p>
  </li>
  <li>
    <p><strong>Convolutional Neural Networks: Detection Algorithm</strong><br />
Coursera, <a href="https://www.coursera.org/learn/convolutional-neural-networks">https://www.coursera.org/learn/convolutional-neural-networks</a>.</p>
  </li>
</ol>


  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="sticky-bottom mt-5">
  <div class="container">
    &copy; Copyright 2021 Fan  Yang.
    
    
    
    Last updated: November 25, 2021.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
